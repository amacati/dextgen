Default:
  n_total_steps: 4_000_000
  eval_interval:  6_400  # Number of training steps between evaluations
  rollouts: 2
  batches: 40
  evals: 10
  batch_size: 256
  buffer_size: 1000000

  gamma: 0.98
  actor_lr: 0.001
  critic_lr: 0.001
  tau: 0.05  # 1-tau is Polyak factor

  eps: 0.3  # Fraction of completely random actions
  noise_process: "Uniform"  # Either Uniform, Gaussian or Ornstein-Uhlenbeck
  noise_process_params: [0., 0.2]  # For Uniform noise: unused. Gaussian noise: mean, variance. For Ornstein-Uhlenbeck: mu, sigma, Optional[clipping]
  k: 4  # Ratio of HER experience vs normal experience

  action_clip: 1.
  state_clip: 200.
  goal_clip: 200.
  grad_clip: 5.
  action_norm: 1.  # Action regularization
  actor_net_type: "DDP"
  actor_net_nlayers: 4
  actor_net_layer_width: 256
  critic_net_nlayers: 4
  critic_net_layer_width: 256

  early_stop: 0.95
  save: True
  load_pretrained: False
  seed: False  # Integer > 0 or False if no custom seed should be used

# Environment specific configurations. Arguments overwrite the default config.

# PJ state:
# grip_pos (0:3), grip_rot (3:9), grip_state (9:11), grip_velp (11:14), object_pos (14:17),
# object_rel_pos (17:20), object_rot (20:26), object_rel_rot (26:32), object_velp (32:35),
# object_velr (35:38)

# PJ goal:
# goal_pos (0:3), [for FlatPJOrient: goal_rot (3:9)]

FlatPJSphere-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

FlatPJCube-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

FlatPJCylinder-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

FlatPJMesh-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

FlatPJAll-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

FlatPJOrient-v0:
# Try reducing fraction of random actions?
  goal_norm_idx: [0, 1, 2]  # Orient includes orientation goal that should not be normalized
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]

# grip_pos (0:3), grip_rot (3:6), grip_state (6:8), grip_velp (8:11), object_pos (11:14),
# object_rel_pos (14:17), object_rot (17:20), object_rel_rot (20:23), object_velp (23:26),
# object_velr (26:29)

FlatPJOrientEuler-v0:
  actor_net_type: "DDP"

FetchPickAndPlace-v1:
  actor_net_type: "DDP"

FlatPJOrientQuat-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]
  actor_net_type: "DDP"

FlatPJOrientAxisAngle-v0:
  state_norm_idx: [0, 1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37]
  actor_net_type: "DDP"