cartpole:
  n_episodes: 1000
  gamma: 1
  lr: 0.001
  eps_max: 1.
  eps_min: 0.01
  buffer_size: 10000
  batch_size: 256
  save_policy: False

pendulum:
  n_episodes: 500
  gamma: 0.99
  buffer_size: 30000
  actor_lr: 0.00005
  critic_lr: 0.0005
  tau: 0.001
  batch_size: 256
  update_delay: 2
  noise_mu: 0.15
  noise_sigma: 0.2
  save_policy: True

lunarlander_ppo:
  n_episodes: 3000
  gamma: 0.99
  actor_lr: 0.00001
  critic_lr: 0.001
  batch_size: 256
  epsilon: 0.2              # Clipping value
  train_iterations: 20
  save_policy: True

# Parameters are shared across ddp processes, effective sizes multiply by WORLD_SIZE
# Example: Effective batch size is batch_size * WORLD_SIZE
lunarlander_ddpg:
  epochs: 200
  cycles: 50
  episodes: 2
  train_episodes: 5
  gamma: 0.99
  buffer_size: 5000
  actor_lr: 0.00005
  critic_lr: 0.0005
  tau: 0.001
  batch_size: 16
  update_delay: 2
  mu: 0.15
  sigma: 0.2
  save_policy: True
  n_episodes: 300  # DEPRECATED

fetchreach_ddpg:
  epochs: 200
  cycles: 50
  episodes: 1
  train_episodes: 10
  gamma: 0.99
  buffer_size: 30000
  actor_lr: 0.00005
  critic_lr: 0.0005
  tau: 0.001
  batch_size: 128
  update_delay: 2
  noise_mu: 0.15
  noise_sigma: 0.2
  save_policy: True